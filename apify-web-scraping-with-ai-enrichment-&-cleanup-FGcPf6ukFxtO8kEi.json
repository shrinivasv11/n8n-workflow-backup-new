{"updatedAt":"2025-11-10T09:51:34.585Z","createdAt":"2025-11-07T07:16:58.683Z","id":"FGcPf6ukFxtO8kEi","name":"Apify Web Scraping with AI Enrichment & Cleanup","active":false,"isArchived":false,"nodes":[{"parameters":{"operation":"Run actor and get dataset","actorId":{"__rl":true,"value":"moJRLRc85AitArpNN","mode":"list","cachedResultName":"Web Scraper (apify/web-scraper)","cachedResultUrl":"https://console.apify.com/actors/moJRLRc85AitArpNN/input"},"customBody":"={\n  \"startUrls\": {{ JSON.stringify($input.all().map(i => i.json)) }},\n  \"breakpointLocation\": \"NONE\",\n  \"browserLog\": false,\n  \"closeCookieModals\": false,\n  \"debugLog\": false,\n  \"downloadCss\": true,\n  \"downloadMedia\": true,\n  \"excludes\": [\n    { \"glob\": \"/**/*.{png,jpg,jpeg,webp,svg,gif,mp4,mp3,pdf}\" }\n  ],\n  \"globs\": [],\n  \"headless\": true,\n  \"ignoreCorsAndCsp\": false,\n  \"ignoreSslErrors\": false,\n  \"injectJQuery\": true,\n  \"keepUrlFragments\": false,\n  \"linkSelector\": \"a[href*='contact'], a[href*='about'], a[href*='company'], a[href*='impressum'], a[href*='support'], a[href*='team'], a[href^='mailto:'], a[href^='tel:']\",\n  \"pageFunction\": \"// Generic company info extractor (name, email, phone, address) with same-domain, shallow crawl\\nasync function pageFunction(context) {\\n  const $ = context.jQuery;\\n  const url = context.request.url;\\n  const origin = new URL(url).origin;\\n\\n  // ----- helpers -----\\n  const clean = (s) => (s || '').replace(/\\\\s+/g, ' ').trim();\\n  const uniq = (arr) => Array.from(new Set((arr || []).filter(Boolean)));\\n  const texts = (sel) => $(sel).map((_, el) => clean($(el).text())).get().filter(Boolean);\\n\\n  // Collect JSON-LD blocks\\n  const jsonLd = [];\\n  $(\\\"script[type='application/ld+json']\\\").each((_, el) => {\\n    try {\\n      const data = JSON.parse($(el).text());\\n      if (Array.isArray(data)) jsonLd.push(...data); else jsonLd.push(data);\\n    } catch(e) {}\\n  });\\n\\n  // Email & phone patterns\\n  const emailRegex = /[A-Z0-9._%+-]+@[A-Z0-9.-]+\\\\.[A-Z]{2,}/gi;\\n  const phoneRegex = /(\\\\+\\\\d{1,3}[\\\\s-]?)?(?:\\\\(?\\\\d{2,4}\\\\)?[\\\\s-]?)?\\\\d{3,4}[\\\\s-]?\\\\d{3,4}(?:[\\\\s-]?\\\\d{2,4})?/g; // lenient intl\\n\\n  // Address helpers\\n  const pullPostalAddress = (node) => {\\n    const n = node || {};\\n    const pa = n.address || n['@type']==='PostalAddress' ? n.address : null;\\n    const addr = pa && typeof pa === 'object' ? {\\n      street: pa.streetAddress || null,\\n      city: pa.addressLocality || null,\\n      state: pa.addressRegion || null,\\n      postal_code: pa.postalCode || null,\\n      country: pa.addressCountry || null\\n    } : null;\\n    return addr;\\n  };\\n\\n  const chooseName = (candidates) => {\\n    // prefer JSON-LD name, then og:site_name, then header/logo alt, then title sans suffix\\n    for (const c of candidates) if (c) return c;\\n    return null;\\n  };\\n\\n  // ---------- JSON-LD / microdata ----------\\n  const orgBlocks = jsonLd.filter(x => x && (x['@type']==='Organization' || x['@type']==='LocalBusiness' || (Array.isArray(x['@type']) && x['@type'].includes('Organization'))));\\n  const org = orgBlocks[0] || null;\\n\\n  // From microdata\\n  const microName = $(\\\"[itemtype*='Organization'] [itemprop='name']\\\").first().text().trim() || null;\\n  const microTel = $(\\\"[itemprop='telephone']\\\").map((_,e)=>clean($(e).text())).get();\\n  const microEmail = $(\\\"[itemprop='email']\\\").map((_,e)=>clean($(e).text())).get();\\n\\n  // Meta fallbacks\\n  const metaOgSite = $(\\\"meta[property='og:site_name']\\\").attr('content');\\n  const metaOgTitle = $(\\\"meta[property='og:title']\\\").attr('content');\\n  const title = $('title').first().text();\\n\\n  // Header/footer cues\\n  const headerName = $('header img[alt], .site-logo img[alt], .navbar-brand, header [class*=\\\"logo\\\"], header h1, header h2').first().attr('alt') || $('header .navbar-brand, header [class*=\\\"logo\\\"], header h1, header h2').first().text();\\n  const footerBlock = clean($('footer').text());\\n\\n  // Emails & phones from links\\n  const mailtos = $('a[href^=\\\"mailto:\\\"]').map((_,a)=>($(a).attr('href')||'').replace(/^mailto:/,'').split('?')[0]).get();\\n  const tels = $('a[href^=\\\"tel:\\\"]').map((_,a)=>($(a).attr('href')||'').replace(/^tel:/,'')).get();\\n\\n  // Emails & phones from visible text (page and footer)\\n  const bodyText = clean($('body').text());\\n  const textEmails = (bodyText.match(emailRegex) || []).map(clean);\\n  const textPhones = (bodyText.match(phoneRegex) || []).map(clean);\\n\\n  // Addresses: JSON-LD first, then common selectors, then heuristics\\n  const jsonAddr = org ? pullPostalAddress(org) : null;\\n  const addrSelectors = [\\n    \\\".address, .addr, [itemprop='address']\\\",\\n    \\\"footer .address, footer [itemprop='address']\\\",\\n    \\\".contact-address, .company-address, .location\\\"\\n  ];\\n  const selectorAddrs = uniq(addrSelectors.flatMap(sel => texts(sel))).filter(t => t.length > 15);\\n\\n  // Heuristic: lines that look addressy (street + city + postal)\\n  const lines = bodyText.split(/\\\\n|\\\\r|\\\\.|\\\\|/).map(clean).filter(Boolean);\\n  const addressish = lines.filter(l => /street|road|rd\\\\b|avenue|sector|phase|block|area|park|industrial|estate|tower|floor|plot|near|opp\\\\.|opp\\\\b|building|lane|soho|suite|apt|village|taluka|district/i.test(l))\\n    .filter(l => /(\\\\b\\\\d{5}(?:-\\\\d{4})?\\\\b|\\\\b\\\\d{6}\\\\b)/.test(l) || /india|usa|united kingdom|uk|uae|australia|canada|singapore|germany|france|japan|china|netherlands|spain|italy/i.test(l));\\n\\n  // Company name candidates\\n  const nameCandidates = uniq([\\n    org && org.name,\\n    microName,\\n    metaOgSite,\\n    metaOgTitle,\\n    clean(headerName),\\n    clean(title && title.replace(/\\\\s*[\\\\-|•|–|—].*$/,''))\\n  ]);\\n  const companyName = chooseName(nameCandidates);\\n\\n  // Final collections\\n  const emails = uniq(mailtos.concat(microEmail).concat(textEmails));\\n  const phones = uniq(tels.concat(microTel).concat(textPhones)).map(p => p.replace(/\\\\s{2,}/g,' '));\\n\\n  const addresses = [];\\n  if (jsonAddr) {\\n    addresses.push(jsonAddr);\\n  }\\n  selectorAddrs.concat(addressish).slice(0, 10).forEach(t => {\\n    // try to split into parts if possible\\n    const pin = (t.match(/\\\\b\\\\d{6}\\\\b/) || [null])[0] || (t.match(/\\\\b\\\\d{5}(?:-\\\\d{4})?\\\\b/) || [null])[0];\\n    addresses.push({\\n      raw: t,\\n      postal_code: pin\\n    });\\n  });\\n\\n  // ---------- enqueue a few relevant same-domain pages (depth <= 2) ----------\\n  const depth = (context.request.userData && context.request.userData.depth) || 0;\\n  if (depth < 2) {\\n    $(\\\"a[href]\\\").each(async (_, a) => {\\n      const href = $(a).attr('href');\\n      if (!href) return;\\n      try {\\n        const next = new URL(href, url);\\n        if (next.origin !== origin) return; // same-domain only\\n        const h = next.href.toLowerCase();\\n        if (/contact|about|company|impressum|support|team|locations|office/.test(h)) {\\n          await context.enqueueRequest({ url: next.href, userData: { depth: depth + 1 } });\\n        }\\n      } catch(e) {}\\n    });\\n  }\\n\\n  // Best-guess single address (prefer JSON-LD structured)\\n  let best_address = null;\\n  if (jsonAddr) best_address = jsonAddr; else if (addresses.length) best_address = addresses[0];\\n\\n  return {\\n    source: url,\\n    domain: origin,\\n    company_name: companyName || null,\\n    emails: emails,\\n    phones: phones,\\n    addresses: addresses,\\n    best_guess: {\\n      name: companyName || null,\\n      email: emails[0] || null,\\n      phone: phones[0] || null,\\n      address: best_address || null\\n    }\\n  };\\n}\\n\",\n  \"postNavigationHooks\": \"[\\n  async (crawlingContext) => {\\n    // Optional: dismiss common cookie banners here if needed.\\n  }\\n]\",\n  \"preNavigationHooks\": \"[\\n  async (crawlingContext, gotoOptions) => {\\n    gotoOptions.waitUntil = 'networkidle2';\\n    gotoOptions.timeout = 60000;\\n  }\\n]\",\n  \"proxyConfiguration\": { \"useApifyProxy\": true },\n  \"respectRobotsTxtFile\": true,\n  \"runMode\": \"DEVELOPMENT\",\n  \"useChrome\": false,\n  \"waitUntil\": [\"networkidle2\"]\n}","timeout":{},"memory":4096},"type":"@apify/n8n-nodes-apify.apify","typeVersion":1,"position":[-304,160],"id":"0fa604d4-73a7-49b7-9d27-256f61790ffb","name":"Run an Actor and get dataset","credentials":{"apifyApi":{"id":"yN37yrPA1ePXOJTp","name":"Apify account"}}},{"parameters":{},"name":"Manual Trigger","type":"n8n-nodes-base.manualTrigger","typeVersion":1,"position":[-736,160],"id":"d5221314-4b0e-4a7f-8648-4f05fef68d02"},{"parameters":{"promptType":"define","text":"={{ $json }}","options":{"systemMessage":"=Role\nYou are a data enrichment and normalization assistant.\nYour task is to take raw scraped content (strings or key–value pairs) from web pages and produce a clean, complete, and structured company profile.\n\nInput\nA JSON object containing fields scraped by Apify (e.g. source, domain, company_name, emails, phones, addresses, best_guess, raw_notes, html, text, or others).\nThe content may include HTML tags, scripts, boilerplate, or unrelated text (like cookie notices or disclaimers).\n\nTask Overview\nYou must:\n\nClean → remove irrelevant or noisy text\n\nExtract → detect and normalize key company data\n\nEnrich → fill missing fields logically using strong inference from context\n\nDeduplicate → ensure unique, non-redundant data in every field\n\nClean the Text\n\nStrip all HTML, script, and style tags.\n\nCollapse repeated whitespace, line breaks, emojis, and decorative symbols.\n\nRemove boilerplate like cookie consent, newsletters, disclaimers, and navigation text.\n\nKeep only meaningful content describing the company, its services, and contact info.\n\nExtract & Normalize Fields\n\ncompany_name\nPreferred order:\n\nJSON-LD Organization or LocalBusiness.name\n\nMeta og:site_name\n\nHeader/logo alt text or first H1\n\nPage title (trim suffixes like “| …” or “– …”)\nKeep suffixes like “Pvt Ltd”, “LLC”, etc. if part of the official name.\nIf missing, infer from domain (e.g. https://acme.com\n → “Acme”).\n\nwebsite\nUse the canonical homepage (scheme + domain).\nPrefer domain field, else derive from source.\nEnforce https://, remove query params, fragments, and trailing slashes.\n\ndescription\n1–3 concise sentences summarizing what the company does (products, services, audience, value proposition).\nAvoid marketing fluff or slogans.\nIf missing, infer from visible content (e.g. “cloud solutions for logistics” → “Provides cloud-based logistics software solutions”).\n\nindustry\nShort, generic sector term (e.g. “Fintech”, “SaaS”, “E-commerce”, “Healthcare IT”, “EdTech”, “AI/ML”, “Cloud/DevOps”, “Logistics”).\nInfer from keywords in description or page text.\n“payments”, “wallet”, “lending” → Fintech\n“e-commerce”, “shop”, “retail” → E-commerce\n“cloud”, “AWS”, “DevOps”, “Kubernetes” → Cloud/DevOps\n“AI”, “ML”, “LLM” → AI/ML\nUse best-fit category if multiple appear.\n\nlocation\nPrefer structured JSON-LD address (city, state, country).\nElse extract the most complete address or HQ location from the contact/about page.\nFormat as: “City, State, Country”.\nIf no location found but country inferred from domain (.in, .us, .uk), fill country only (e.g. .in → “India”).\n\nemail\nLowercase and clean: remove mailto: and query parameters.\nPrefer domain-based emails (info@domain.com\n, contact@domain.com\n).\nIf missing, infer a general contact email: info@<domain>.\nExclude Gmail/Yahoo/Outlook unless that’s the only one available.\nIf multiple emails found:\n\nRemove duplicates (case-insensitive).\n\nKeep only the first valid domain-based email.\n\nphone\nNormalize to E.164 format (+<countrycode><number>).\nIf format not possible, use cleaned numeric version.\nPrefer the first valid main/sales/support number.\nIf multiple phones found:\n\nDeduplicate by digits only.\n\nKeep the most complete (longest) valid number.\n\nlinkedin\nCanonicalize company profile URL: https://www.linkedin.com/company/\n<slug>/\nExtract from any link containing linkedin.com/company/ or linkedin.com/in/.\nIf multiple found, keep only one canonicalized company link.\n\ntwitter\nCanonicalize Twitter/X URL: https://twitter.com/\n<handle>\nExtract from any link containing twitter.com or x.com.\nIf multiple found, keep only one canonicalized link.\n\ntechnologies\nArray of distinct tools or frameworks mentioned in the text, such as:\n[“React”, “Angular”, “TypeScript”, “Java”, “Spring Boot”, “Node.js”, “Python”, “Django”, “AWS”, “Azure”, “GCP”, “Docker”, “Kubernetes”, “PostgreSQL”, “MySQL”, “MongoDB”, “Redis”, “Terraform”, “Jenkins”, “GitHub Actions”, “Bitbucket Pipelines”, “Shopify”, “WordPress”, “GA4”, “Mixpanel”, “Segment”, “Stripe”]\nDeduplicate, keep consistent casing (AWS, React, Next.js, GA4).\nIf technologies are not mentioned, leave as an empty array.\n\nDeduplication Rules\nWhenever multiple values appear for the same field:\n\nRemove exact and near-duplicate entries.\n\nTrim whitespace, punctuation, and normalize casing before comparison.\n\nKeep the most relevant, official, and domain-consistent entry.\n\nFor arrays (emails, phones, technologies) → return unique, sorted, clean items.\n\nFor single-value fields (company_name, website, description, etc.) → pick one canonical value.\n\nHeuristics & Inference\nAlways prefer structured data > meta > visible text.\nInfer only when strongly implied (e.g. “payment gateway” → Fintech).\nNever fabricate details (no fake phone/email).\nIf multiple candidates exist, select the most authoritative and consistent set.\n\nValidation & Formatting\nEmails: must match a valid email regex.\nPhones: digits only, no extra spaces, dashes, or extensions.\nSocial links: only one canonical LinkedIn & Twitter each.\nDescription: 20–300 characters.\n\nOutput Format\nReturn strict JSON, no comments or markdown:\n{\n\"company_name\": \"\",\n\"website\": \"\",\n\"description\": \"\",\n\"industry\": \"\",\n\"location\": \"\",\n\"email\": \"\",\n\"phone\": \"\",\n\"linkedin\": \"\",\n\"twitter\": \"\",\n\"technologies\": []\n}\n\nBehavior for Missing Fields\nIf a field is missing:\nTry to infer logically (from text, domain, or metadata).\nIf no reliable inference, leave it as null or an empty string.\nNever fabricate fake or unrelated data."}},"type":"@n8n/n8n-nodes-langchain.agent","typeVersion":3,"position":[-64,160],"id":"a5865380-30c8-4d1a-9e08-d6c575ec2daa","name":"AI data enrichment agent"},{"parameters":{"promptType":"define","text":"={{ $json.output }}","options":{"systemMessage":"=Role\nYou are a data cleanup and normalization assistant.\nYour job is to take structured but inconsistent JSON data (output from the data enrichment step) and standardize, validate, deduplicate, and correct all fields for accuracy and consistency, ensuring a single canonical value per field.\n\nInput\nA JSON object in this exact structure:\n{\n\"company_name\": \"\",\n\"website\": \"\",\n\"description\": \"\",\n\"industry\": \"\",\n\"location\": \"\",\n\"email\": \"\",\n\"phone\": \"\",\n\"linkedin\": \"\",\n\"twitter\": \"\",\n\"technologies\": []\n}\nThe data may contain formatting issues, duplicates, partial information, or multiple conflicting candidates carried over from previous steps.\n\nTask Overview\nYour job is to clean, validate, normalize, and deduplicate this data without changing factual content beyond permissible normalization/inference rules. Make the output consistent, properly formatted, and database-ready. Enforce a single-record guarantee: one authoritative value for each single-value field.\n\nGlobal Rules\n\nTrim extra spaces, tabs, and line breaks.\n\nRemove emojis, symbols, zero-width characters, and unnecessary punctuation.\n\nNormalize to standard ASCII where possible (preserve legit accented characters in names).\n\nConvert obvious placeholders to null: \"\", \" \", \"N/A\", \"NA\", \"n/a\", \"none\", \"null\", \"undefined\", \"-\", \"--\", \"[object Object]\".\n\nCollapse repeated punctuation (e.g., \"Inc..\", \"— —\").\n\nIf a field has multiple candidates (e.g., from merged agents), apply the field-specific precedence rules below to choose one canonical value and discard the rest.\n\nCross-field consistency: prefer values aligned to the canonical website domain; when conflicts arise, favor domain-consistent values.\n\nSingle-Record & Deduplication Policy\n\nFor single-value fields (company_name, website, description, industry, location, email, phone, linkedin, twitter): return exactly one canonical value or null.\n\nFor technologies: return a unique, normalized, alphabetically sorted array (max 20).\n\nIf multiple candidates exist, remove duplicates using case-insensitive comparison after trimming, decoding, and canonicalizing; then select one using the field’s precedence rules.\n\nRemove trailing/leading punctuation and duplicated words (e.g., \"Acme Acme Pvt Ltd\" → \"Acme Pvt Ltd\").\n\nPriority Sources (when multiple candidates present)\n\nAlready normalized/valid values that match canonical patterns (e.g., LinkedIn company URL format).\n\nValues aligned to the canonical website domain.\n\nThe longest, most complete value that remains valid after normalization.\n\nEarliest candidate encountered (stable tie-breaker) if still indistinguishable.\n\nField-by-Field Rules\n\ncompany_name\n\nTitle-case company name (e.g., “acme technologies pvt ltd” → “Acme Technologies Pvt Ltd”).\n\nRemove trailing dots or duplicate words.\n\nKeep official suffixes: “Pvt Ltd”, “LLC”, “Inc.”, “GmbH”, “Ltd”, “S.A.”, “SAS”, “BV”, “Oy”, etc.\n\nIf multiple names, prefer the one that:\na) Contains a recognized legal suffix; else\nb) Matches/contains the website root brand; else\nc) Is longest without marketing slogans.\n\nIf missing but website exists, infer from domain (e.g., “https://zencloud.io”\n → “Zencloud”).\n\nIf result is <2 characters after cleanup, set to null.\n\nwebsite\n\nEnsure it starts with https://.\n\nKeep only scheme + registrable domain (strip path, query, fragment, trailing slash).\n\nLowercase domain.\n\nExample: “http://ACME.com/about?ref=google”\n → “https://acme.com”\n.\n\nIf multiple domains, prefer:\na) HSTS/https-capable (assume https); then\nb) Corporate TLD over generic page hosts (avoid link shorteners); then\nc) Domain matching email/social handles; else the shortest registrable.\n\nIf invalid URL or IP-only without domain, set to null.\n\ndescription\n\nRemove filler like “Welcome to”, “We are passionate about”, “Our mission is to”, “Leading provider of”, “We strive to”.\n\nKeep factual details on products/services/audience/purpose.\n\nLimit to 20–300 characters. If longer, trim smartly at sentence boundaries; if shorter, keep as-is if meaningful.\n\nEnsure it ends with a period.\n\nIf multiple variants, choose the most specific, jargon-light, product/service-focused sentence.\n\nIf only slogans remain, set to null.\n\nindustry\n\nNormalize to a controlled vocabulary in Title Case (e.g., “SaaS”, “Fintech”, “E-commerce”, “Healthcare IT”, “AI/ML”, “Cloud/DevOps”, “Logistics”, “EdTech”, “PropTech”, “HR Tech”, “MarTech”, “Cybersecurity”, “Analytics/BI”).\n\nIf ambiguous or conflicting, set to null (do not guess).\n\nIf multiple options, choose the one most aligned with the description and website content keywords; otherwise null.\n\nlocation\n\nFormat as “City, State, Country” when available.\n\nRemove postal codes and contact artifacts (e.g., “Pin-411057”, “Tel: +91...”).\n\nCapitalize each part properly.\n\nIf multiple locations, keep HQ or the first valid address; favor the one that appears with “Head Office”, “HQ”, or on the main contact section.\n\nIf only country is known, return “Country”. If nothing reliable, set to null.\n\nemail\n\nLowercase and validate via basic regex.\n\nStrip “mailto:” and query parameters.\n\nIf multiple emails, prefer:\na) Domain-based email matching the website domain; then\nb) The first valid non-free provider; then\nc) The first valid email.\n\nExample: “mailto:INFO@acme.com?subject=hi” → “info@acme.com\n”.\n\nIf invalid after cleanup, set to null.\n\nDo not fabricate or infer a new email address here.\n\nphone\n\nRemove spaces, dashes, brackets, slashes, dots, and extensions (ext/x/#); keep digits and leading plus.\n\nNormalize to E.164 (+<countrycode><number>).\n\nIf country code missing and location or TLD strongly implies country, infer country code (.in or “India” → +91, .us/“United States” → +1, .uk/“United Kingdom” → +44, .ae → +971, .au → +61, .ca → +1).\n\nIf multiple numbers, choose:\na) The valid E.164 with country code matching inferred location or TLD; then\nb) The longest valid number; then\nc) The first valid number.\n\nIf invalid or incomplete after normalization, set to null.\n\nlinkedin\n\nEnsure URL matches: https://www.linkedin.com/company/\n<slug>/\n\nConvert any linkedin.com/in/... or linkedin.com/showcase/... to the company pattern only if clearly convertible; otherwise set to null.\n\nRemove tracking parameters and enforce trailing slash.\n\nLowercase the path.\n\nIf multiple links, keep the first valid canonical company URL.\n\ntwitter\n\nEnsure URL matches: https://twitter.com/\n<handle>\n\nConvert x.com and www\n. variants to twitter.com; remove params; lowercase handle; no trailing slash after handle.\n\nIf multiple links, keep the first valid canonical URL.\n\nIf only hashtags or intent links exist, set to null.\n\ntechnologies\n\nNormalize names (e.g., “react.js”, “reactJS” → “React”; “aws cloud”, “Amazon Web Services” → “AWS”; “g.a.4” → “GA4”; “Nextjs” → “Next.js”).\n\nTitle-case where appropriate; keep canonical casing for brands/acronyms (AWS, GCP, GA4, SQL, .NET, Next.js).\n\nDeduplicate (case-insensitive) and sort alphabetically.\n\nLimit to max 20 entries (keep the most core/unique; drop generic duplicates).\n\nRemove generic non-tech words (e.g., “Technology”, “Web”, “App”, “Services”).\n\nCross-Field Consistency Checks\n\nIf email domain differs from website domain and both are valid, prefer keeping the email only if it’s clearly corporate (not free provider) and plausibly related; otherwise keep it but do not modify. Do not create a new email.\n\nIf LinkedIn/Twitter handles include the website brand string, prefer those when choosing among multiple candidates.\n\nIf phone country code conflicts with location country, prefer the one consistent with location; if still conflicting, keep the valid E.164 and set location to country-only if necessary.\n\nIf company_name appears to be just the domain with TLD (e.g., “acme.com”), remove TLD (“Acme”).\n\nEnsure no field repeats in another (e.g., description should not equal company_name).\n\nValidation\n\nEmail: basic regex; must contain one “@” and a valid domain TLD; no spaces.\n\nWebsite: valid https URL with registrable domain; no paths/queries/fragments.\n\nLinkedIn: must match https://www.linkedin.com/company/\n<slug>/\n\nTwitter: must match https://twitter.com/\n<handle>\n\nPhone: E.164 or null.\n\nDescription: 20–300 chars, ends with a period.\n\nOutput Rules\n\nOutput only the cleaned JSON in the same schema:\n{\n\"company_name\": \"\",\n\"website\": \"\",\n\"description\": \"\",\n\"industry\": \"\",\n\"location\": \"\",\n\"email\": \"\",\n\"phone\": \"\",\n\"linkedin\": \"\",\n\"twitter\": \"\",\n\"technologies\": []\n}\n\nDo not include explanations, comments, or markdown.\n\nEvery string must be trimmed and normalized.\n\nIf a field is missing, invalid, ambiguous, or fails validation after cleanup, set it to null.\n\nThe process must be deterministic and idempotent: running it multiple times on the same input yields the same output.\n\nTie-Breakers (Deterministic)\n\nWhen multiple candidates remain after validation:\n\nPrefer candidate whose domain or brand matches the website domain.\n\nPrefer the longest valid normalized candidate that adds information (not just longer due to tracking params, which must be removed first).\n\nPrefer the earliest occurrence in the provided input order as final tie-breaker.\n\nExamples of Canonicalization (implicit behavior)\n\n“http://ACME.com/about?ref=google”\n → “https://acme.com”\n\n“mailto:SALES@Acme.io?subject=Hello” → “sales@acme.io\n”\n\n“+91 98765-43210 ext 204” → “+919876543210”\n\n“https://x.com/AcmeTech?t=123”\n → “https://twitter.com/acmetech”\n\n“https://www.linkedin.com/in/acme/”\n → null (not a company page)\n\n[“aws”, “python”, “react”, “react”] → [“AWS”, “Python”, “React”]"}},"type":"@n8n/n8n-nodes-langchain.agent","typeVersion":3,"position":[240,160],"id":"8fb0198a-a926-4aea-9d9e-56770a5ea3ab","name":"AI data cleanup agent"},{"parameters":{"options":{}},"type":"@n8n/n8n-nodes-langchain.lmChatGoogleGemini","typeVersion":1,"position":[-64,384],"id":"0008c076-651e-4c7f-ac21-667dfb728cb9","name":"Google Gemini Chat Model","credentials":{"googlePalmApi":{"id":"2dYCQEJmlRAbJ0ZK","name":"edwin-gemini-api-key"}}},{"parameters":{"options":{}},"type":"@n8n/n8n-nodes-langchain.lmChatGoogleGemini","typeVersion":1,"position":[240,384],"id":"1717fb98-dfb0-4f7e-93a3-fb2d5870ad52","name":"Google Gemini Chat Model1","credentials":{"googlePalmApi":{"id":"2dYCQEJmlRAbJ0ZK","name":"edwin-gemini-api-key"}}},{"parameters":{"jsCode":"// Add your URLs here\nconst urls = [\n  \"https://iworktech.com\",\n];\n\n// Convert to Apify-style startUrls format\nreturn urls.map(url => ({\n  json: {\n    url,\n    method: \"GET\",\n    userData: { depth: 0 }\n  }\n}));\n"},"type":"n8n-nodes-base.code","typeVersion":2,"position":[-528,160],"id":"75f899ab-157b-4377-8330-7bcf3f5448d5","name":"Input Compny_URL"},{"parameters":{"tableId":"company_data","dataToSend":"autoMapInputData"},"type":"n8n-nodes-base.supabase","typeVersion":1,"position":[768,160],"id":"1c2fad36-9641-494e-8666-086ff66c4937","name":"Create a row","credentials":{"supabaseApi":{"id":"d8px7xRtHhyacU4j","name":"Supabase account"}}},{"parameters":{"jsCode":"// Input: items like { json: { output: \"```json { ... } ```\" } }\n// Output: one item per row with clean fields ready for Supabase\n\nfunction stripCodeFences(s) {\n  if (!s || typeof s !== 'string') return s;\n  // remove ```json ... ``` or ``` ... ```\n  s = s.trim();\n  s = s.replace(/^```json\\s*/i, '');\n  s = s.replace(/^```\\s*/i, '');\n  s = s.replace(/```$/i, '').trim();\n  return s;\n}\n\n// Normalize nullables and ensure technologies is array/json-safe\nfunction toRow(obj) {\n  const row = {\n    company_name: obj.company_name ?? null,\n    website: obj.website ?? null,\n    description: obj.description ?? null,\n    industry: obj.industry ?? null,\n    location: obj.location ?? null,\n    email: obj.email ?? null,\n    phone: obj.phone ?? null,\n    linkedin: obj.linkedin ?? null,\n    twitter: obj.twitter ?? null,\n    technologies: Array.isArray(obj.technologies) ? obj.technologies : [],\n  };\n  return row;\n}\n\nconst out = [];\n\nfor (const item of items) {\n  let raw = item.json?.output ?? item.output ?? item.json ?? null;\n  if (raw == null) continue;\n\n  // If nested as string, strip code fences and parse.\n  if (typeof raw === 'string') {\n    let s = stripCodeFences(raw);\n    try {\n      const obj = JSON.parse(s);\n      out.push({ json: toRow(obj) });\n      continue;\n    } catch (e) {\n      // If it already was a plain JSON string without fences but with small issues,\n      // try a second chance removing stray backticks.\n      try {\n        const obj = JSON.parse(s.replace(/`/g, ''));\n        out.push({ json: toRow(obj) });\n        continue;\n      } catch {}\n    }\n  }\n\n  // If it’s already an object (some items in your sample are)\n  if (typeof raw === 'object' && raw !== null) {\n    out.push({ json: toRow(raw) });\n  }\n}\n\nreturn out;\n"},"type":"n8n-nodes-base.code","typeVersion":2,"position":[560,160],"id":"53474aa1-5ac4-42f2-9c79-9778d42b539d","name":"Map's the data to database"}],"connections":{"Manual Trigger":{"main":[[{"node":"Input Compny_URL","type":"main","index":0}]]},"Run an Actor and get dataset":{"main":[[{"node":"AI data enrichment agent","type":"main","index":0}]]},"AI data enrichment agent":{"main":[[{"node":"AI data cleanup agent","type":"main","index":0}]]},"Google Gemini Chat Model":{"ai_languageModel":[[{"node":"AI data enrichment agent","type":"ai_languageModel","index":0}]]},"Google Gemini Chat Model1":{"ai_languageModel":[[{"node":"AI data cleanup agent","type":"ai_languageModel","index":0}]]},"AI data cleanup agent":{"main":[[{"node":"Map's the data to database","type":"main","index":0}]]},"Input Compny_URL":{"main":[[{"node":"Run an Actor and get dataset","type":"main","index":0}]]},"Map's the data to database":{"main":[[{"node":"Create a row","type":"main","index":0}]]}},"settings":{"executionOrder":"v1"},"staticData":null,"meta":{"templateCredsSetupCompleted":true},"pinData":{},"versionId":"e4ae1bd9-abff-4411-880f-dbb23a3ce217","triggerCount":0,"shared":[{"updatedAt":"2025-11-07T07:16:58.683Z","createdAt":"2025-11-07T07:16:58.683Z","role":"workflow:owner","workflowId":"FGcPf6ukFxtO8kEi","projectId":"tsuA2t8C154Ytetn"}],"tags":[]}